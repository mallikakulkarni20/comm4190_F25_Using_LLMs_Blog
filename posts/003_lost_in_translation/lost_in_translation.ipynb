{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cfb42-6318-4cbe-8d5b-f8d0ec87ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: \"Lost in Translation\"\n",
    "description: \"How far can language bend before it breaks?\" \n",
    "author: \"Mallika Kulkarni\"\n",
    "date: \"9/8/2025\"\n",
    "categories:\n",
    "  - Language\n",
    "  - Sentiment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f26a94-3339-476d-a814-ef4c631493d2",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "How far can language bend before it breaks? Technically forever. Common consensus is that with language anything can be communicated, so meaning should be consistent among translation. Human sentiment can be one of the most important things with language and **we must test whether an LLM can interpret that sentiment**. Otherwise, it will fail with repeated translation.\n",
    "\n",
    "I used some of the most commonly spoken languages in order to favor the GPT as much as possible.\n",
    "In this experiment, I ran several English paragraphs through a **language** chain using Claude because Anthropic has tested better for language skills:\n",
    "\n",
    "#### English → Hindi → Spanish → back to English\n",
    "\n",
    "My goal was to test **prompt chaining** across different types of text and see how meaning and nuance is interpreted by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ee57e-e61d-4d5e-884b-80b6ea24dfcd",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For each test, I used GPT-4o and prompted it to do the following:\n",
    "\n",
    "Translate the source paragraph from English to Hindi, then translate that Hindi paragraph to Spanish, then translate that Spanish back to English.\n",
    "\n",
    "\n",
    "\n",
    "I conducted these translations separately, by copy and pasting into different prompting chats. This way GPT retained no knowledge between past prompt and did not just recall an earlier prompt.\n",
    "All translations were done separately, in sequence. I also want to be able to see this linguistic drift in 2 different contexts: a very casual conversation as well as a technical conversation. I predict that there will be less drift in a technical conversation because it will rely more on direct word translation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
