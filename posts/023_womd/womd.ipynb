{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1d06ad3b-a8c3-4ed3-952b-9bd4660227f5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Weapons of Math Destruction\"\n",
    "description: \"Review of a book about models\" \n",
    "author: \"Mallika Kulkarni\"\n",
    "date: \"12/2/2025\"\n",
    "categories:\n",
    "  - Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b6e40-a0c4-425d-8898-a10bf498d984",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "A couple years ago, I read a book by Cathy O'Neil, called Weapons of Math Destruction. I thought it's description of mathematical models was relevant to our current environment of AI and Machine Learning. I also thought it would be a nice change to share my thoughts rather than another prompting blog!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c04a0-a5e8-41a2-b96d-19f000b86b72",
   "metadata": {},
   "source": [
    "# Thoughts\n",
    "\n",
    "In “Weapons of Math Destruction,” Cathy O’Neil highlights the dangers of mathematical models that are not controlled and overseen by humans. I completely agree that models without human supervision that are given complete power to make decisions can be extremely dangerous. She mentions that though people may have good intentions, it may not be enough with big data and a black box model, especially with sensitive information ranging from socioeconomic status to racial background. I agree and resonate with this because I used to research specific dangers of biased data; while humans can try to filter input data and outputs of models as much as they can, nobody can correctly ascertain what is right or wrong. \n",
    "\n",
    "I also believe that sometimes an incorrect outcome can outweigh the benefits of a hundred correct outcomes, specifically shown through the teacher evaluation algorithm that O’Neil demonstrates. This idea connects with the responsibilities of two actors, and neither has the software. “Weapons of Math Destruction” portrays that first comes the oversight, the people deploying these models and marketing them to communities who are the most uneducated about emerging technology, the other would be the data scientists who, while focused on the technology, are not always focused on the repercussions. For this reason, we need to make sure that these overseers and data scientists both communicate the effects of the AI and data to those uninvolved in the tech building process ranging from policy makers to the general public. We must consider this as society has to make decisions about AI.  \n",
    "\n",
    "The Association for the Advancement of AI stated that some mechanisms must be in place, including limiting the AI to an assistant and having humans detect its bad behavior. I thought this was interesting and significant because these are external mechanisms that could solve some of the problems that Cathy O’Neil brought up. I believe that there should instead be societal and non-engineering checks on the AI rather than a programmer-only bias check. I also think that this leads to too much blame placed on data scientists rather than AI builders and ideators as a whole. ELimiting AI to have assistant-based behavior could help enforce the idea of having human oversight to control and mitigate this bias.\n",
    "\n",
    "While engineers can control biased data used as input in various models, it can be hard to regulate outputs through a black box. Therefore, if AI is used as an assistant, those using the model can regulate and flag this bias once they see it as they test (use) the model.\n",
    "\n",
    "\n",
    "Overall, through “Weapons of Math Destruction”, we can see the algorithmic bias can be hard to control and extremely dangerous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe13851-930d-4afc-b002-d88d475a48b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
