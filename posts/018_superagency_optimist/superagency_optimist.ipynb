{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dc1a0eb1-b3a2-41d7-aa82-f916d4fa9d44",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Reading Superagency as an Optimist\"  \n",
    "description: \"Reading the book with optimism at the forefront of my mind!\"  \n",
    "author: \"Mallika Kulkarni\"  \n",
    "date: \"12/12/2025\"  \n",
    "categories:  \n",
    "- Superagency\n",
    "- Living with a Book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c2e927-a54e-4a9e-aba8-32fc91a68ecb",
   "metadata": {},
   "source": [
    "![](superagency.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61d5d4-1d4c-46d0-afb8-ca71b2f95ade",
   "metadata": {},
   "source": [
    "Halfway through Superagency, I caught myself doing something unexpected. I was nodding along. Not cautiously, not with mental footnotes, but genuinely agreeing. This surprised me, because optimism about AI does not usually come naturally to me. But the book’s framing of AI as a potential amplifier of human agency rather than a replacement for it felt refreshing in a way that did not sound naive.\n",
    "\n",
    "What resonated most was the idea that agency is not binary. We are not either in control or powerless. We exist on a spectrum shaped by tools, institutions, and norms. AI, in this framing, is just another lever. A powerful one, yes, but still something that can be aligned with human goals rather than positioned against them.\n",
    "\n",
    "I liked how the book emphasized augmentation over automation. Instead of focusing on what AI can do instead of us, it asks what AI can help us do better. Better decisions, better coordination, better access to information. That shift matters. It reorients the conversation away from replacement anxiety and toward design responsibility.\n",
    "\n",
    "There was something hopeful in the insistence that outcomes are not predetermined. The book pushes back against the narrative that AI’s trajectory is inevitable and uncontrollable. It argues that policy choices, technical architectures, and cultural expectations actively shape what AI becomes. As someone who studies and builds systems, that argument felt grounding. It reminded me that agency applies not just to users, but to designers, researchers, and lawmakers.\n",
    "\n",
    "Optimism, in this context, did not feel like blind faith. It felt like a challenge. It is a failure of imagination and governance. That framing made optimism feel less like cheerleading and more like accountability.\n",
    "\n",
    "I also appreciated that the book treats human values as something worth preserving and extending, not something to be optimized away. There is an implicit belief that humans still matter in the loop. The optimist in me was not fully convinced that everything will work out, but convinced that it could. Superagency made me want to participate in shaping AI’s future rather than merely critiquing it from the sidelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
